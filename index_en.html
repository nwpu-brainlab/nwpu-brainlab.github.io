<!DOCTYPE html>
<html lang="en">

<head>


    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="namfPrdXk33Ri7iYMv4SKPv4cN23tAPYCuUZWP8yydE" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <style>
        .yahei {
            font-family: 'Microsoft YaHei', "微软雅黑", "黑体", "宋体", sans-serif;
        }
		table#paper_list td {font-size: 1.2em;  }
    </style>

    <title>BRAIN Lab</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/landing-page.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic,700italic" rel="stylesheet"
        type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top topnav" role="navigation">
        <div class="container topnav">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse"
                    data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand topnav" href="#">BRAIN Lab</a>
            </div>
            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="#about"><span class="yahei">About</span></a>
                    </li>
                    <li>
                        <a href="#publications"><span class="yahei">People</span></a>
                    </li>
                    <li>
                        <a href="#direction"><span class="yahei">Research Direction</span></a>
                    </li>
                    <li>
                        <a href="#student"><span class="yahei">Recruitment and Employment</span></a>
                    </li>
					<li>
                        <a href="index.html"><span class="yahei">中文版</span></a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>


    <!-- Header -->
    <a name="home"></a>
    <div class="intro-header">
        <div class="container-fluid">
            <div class="row">
                <div class="col-lg-12">
                    <div class="intro-message">
                        <img src="./img/intro-bg.jpg" width="100%">
                    </div>
                </div>
            </div>

        </div>
        <!-- /.container -->

    </div>
    <!-- /.intro-header -->

    <!-- Page Content -->

    <a name="about"></a>
    <div class="content-section-b">

        <div class="container">
            <div class="row">
                <div class="col-lg-12 col-sm-12">
                    <hr class="section-heading-spacer">
                    <div class="clearfix"></div>
                    <h2 class="section-heading"><span class="yahei">About</span></h2>
                    <p class="lead">
                        <span class="yahei">The Brain and Artificial Intelligence Laboratory (BRAIN Lab) is affiliated to the Key Laboratory of Information Fusion Technology under the Ministry of Education. The team targets at the cutting-edge research in the filed of archifical intelligence and closely focuses on the country's strategic needs. We carry out the theoretical research, key technology breakthroughs, and system integration verification in the fields of intelligent remote sensing information processing, brain cognition and intelligent computing, visual intelligent perception and intelligent processing, etc. By providing new ideas, new methods and new technologies for the development of artificial intelligence, our team has been one of the important bases for the cultivation of high-level talents and high-level scientific research in the field of artificial intelligence in China. Graduates are mainly employed by domestic high-tech companies and domestic research institutes such as Baidu, Alibaba, Tencent, Shangtang Technology, Hikvision, Didi, etc. </span>
                    </p>
                    <img src="img/1.jpg" style="max-height: 100%; max-width: 100%;" />
                    <h2 class="section-heading"><span class="yahei">Recent News:</span></h2>
                    <p>
                        <ul class="lead"> 
						<li class="yahei">Junwei Han and Dingwen Zhang Won Wu Wenjun AI Science and Technology Award, the Highest AI Award in China.</li>
                        <li class="yahei">"Vision-Intelligence" research group's website is now online!<a href="https://vision-intelligence.com.cn/">[WebLink]</a></li>
						<li class="yahei">Professor Junwei Han Have Been Elected Fellow of 2022 International Association for Pattern Recognition(IAPR Fellow)!</li>
						<li class="yahei">5 papers are accepted by ICCV 2021!</li>
						<li class="yahei">"A Weakly Supervised Object Detection Approach Using Point Annotation" is published by Science China: Information Science.</li>
						<li class="yahei">"Scribble-Supervised Video Object Segmentation" is published by IEEE/CAA Journal of Automatica Sinica.</li>
						<li class="yahei">"Learning rotation-invariant convolutional neural networks for object detection in VHR optical remote sensing images" won GRSS Highest Impact Paper Award!</li>
						    <li class="yahei">"A unified metric learning-based framework for co-saliency detection" won the 2021 IEEE TCSVT Best Paper Award!</li>
							<li class="yahei">“Weakly Supervised Object Localization and Detection: A Survey” is accepted by IEEE TPAMI.</li>
							<li class="yahei">“Adaptive Neighborhood Metric Learning” is published by IEEE TPAMI.</li>
							<li class="yahei">“Strengthen Learning Tolerance for Weakly Supervised Object Localization” is accpted by CVPR.</li>
                            <li class="yahei">“Weakly Supervised Video Salient Object Detection” is accpted by CVPR.</li>
							<li class="yahei">Nian Liu obtains CSIG Excellent Doctoral Dissertation Award. Congratulations to Nian!</li>
							<li class="yahei">“Weakly Supervised Object Detection Using Proposal- and Semantic-Level Relationships” is accpted by IEEE TPAMI.</li>
							<li><a style="color:red;" href="WSL.html" target="__blank">T-MM SI on Weakly Supervised Learning for
                                Image and Video Understanding (Submission deadline: Augest 2021)</a></li>
                            <li><a style="color:red;" href="LOVSD.html" target="__blank">T-CSVT SI on Advanced Machine Learning Methodologies for Large-Scale Video Object Segmentation and Detection (Submission deadline: December 2020)</a></p></li>
                            <li class="yahei">We have created a large-scaled benchmark, called <a href="https://github.com/nnizhang/smac">ReDWeb-S</a>, for RGB-D salient object detection.</li>
							<li class="yahei">“Revisiting Anchor Mechanisms for Temporal Action Localization” is accpted by IEEE TIP.</li>
                            <li class="yahei">“Weakly-Supervised Learning of Category-specific 3D Object Shapes” is accpted by IEEE TPAMI.</li>
							<li class="yahei">“Evaluation of Saccadic Scanpath Prediction: Subjective Assessment Database and Recurrent Neural Network Based Metric” is accpted by IEEE TPAMI.</li>
                        </ul>
                </div>
                
            </div>

            <!-- <div class="clearfix"></div> -->
            <a name="publications"></a>
            
            <div class="row">
                <div class="col-lg-12 col-sm-12">
                    <!-- <hr class="section-heading-spacer"> -->

                    <h2 class="section-heading"><span class="yahei">People:</span></h2>
                    <table class="table table-striped table-hover ">
                        <thead>
                            <tr>
                                <th class="col-xs-1"><span class="yahei">Staff</span></th>
                                <th class="col-xs-3"><span class="yahei">Introduction</span></th>
                                <th class="col-xs-1"><span class="yahei">Staff</span></th>
                                <th class="col-xs-3"><span class="yahei">Introduction</span></th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><img src="img/hjw.jpg" style="max-width: 100%;" /></td>
                                <td style="text-align: justify;"><span class="yahei">Junwei Han is currently a Professor in Northwestern Polytechinical University. His research interests include computer vision, pattern recognition, and artifical intelligence. He has published more than 100 papers in top journals and conferences such as Proceedings of the IEEE, TPAMI, CVPR, MICCAI, and so on. He is an Associate Editor of IEEE Trans. on Neural Networks and Learning Systems, IEEE Trans. on Multimedia, IEEE Trans. on Circuits and Systems for Video Technology, and IEEE Trans. on Cybernetics. He also serves CVPR, ICPR, and ACCV as an area chair. Email: junweihan2010@gmail.com</span></td>
                                <td><img src="img/cg.jpg" style="max-width: 100%;" /></td>
                                
                                <td style="text-align: justify;"><span class="yahei">Gong Cheng is currently a Professor with Northwestern Polytechnical University, Xi’an, China. He has published more than 30 papers in top journals and top conferences including Proceedings of the IEEE, IEEE TPAMI, IEEE TIP, CVPR, and so on. 19 of his papers have been recognized as ESI highly cited papers and 11 of them have been recognized as ESI hot papers. His publications have received more than 5400 Google Scholar citations. He is an associate editor or editorial board member of several international journals including IEEE GRSM, IEEE JMASS, IEEE JSTARS, ISPRS JPRS and so on. Homepage：www.escience.cn/people/gongcheng</span></td>
                                </td>
                            </tr>

                            <tr>
                                <td><img src="img/zdw.jpg" style="max-width: 100%;" /></td>
                                <td style="text-align: justify;"><span class="yahei">Dingwen Zhang is a Professor at BRAIN Lab, NWPU. He obtained his B.S. and Ph.D. degrees from School of Automation, Northwestern Polytechnical University (NWPU) in 2012 and 2018, respectively. From Oct. 2015 to Oct. 2017, he worked with Dong Huang and Fernando de la Torre as a visiting PHD student at the Human Sensing Laboratory in Carnegie Mellon University (CMU). He is mainly interested in developing effective computer vision algorithms that are inspired by the human vison and human learning procedure. Currently, he is working on developing weakly supervised learning systems for computer vision tasks like object detection, segmentation, 3D shape reconstruction. Personal Homepage: <a href="https://zdw-nwpu.github.io/dingwenz.github.com/">[Link]</a>. Team Homepage: <a href="https://vision-intelligence.com.cn/">[Link]</a>. </span></td>
                                </td>
                                <td><img src="img/zsj.jpg" style="max-width: 100%;" /></td>
                                <td style="text-align: justify;"><span class="yahei">Shijie Zhao is an associate professor and Master's tutor in Northwestern Polytechnical university of China. In recent years, he has published more than 30 papers in high-level international journals and conferences in the fields of brain imaging analysis and artificial intelligence, such as IEEE TMI, IEEE JBHI, MICCAI, ICME, ACM MM. He is a member of  the Special Committee on Visual Cognition and Computing of Chinese Image Graphics Society and a reviewer in many journals such as IEEE TMI, IEEE JBHI and IEEE SMC. Email:shijiezhao666@gmail.com</span></td>
                            </tr>

                            <tr>
                                <td><img src="img/yxw.jpg" style="max-width: 100%;" /></td>
                                <td style="text-align: justify;"><span class="yahei">Xiwen Yao received the B.S. and Ph.D degrees from Northwestern Polytechnical University, Xi'an, China, in 2010 and 2016, respectively. He is currently an Assocaite Professor with Northwestern Polytechnical University, Xi'an, China. His main research interests include remote sensing image understanding, deep learning, computer vision, and pattern recognition. He has published 26 papers in top journals and top conferences, including IEEE TPAMI, IEEE TIP, IEEE TGRS, ACM MM, and IGARSS. 
								Homepage：https://teacher.nwpu.edu.cn/yaoxiwen.html</span></td>
                                <td><img src="img/cxy.jpg" style="max-width: 100%;" /></td>
                                <td style="text-align: justify;"><span class="yahei">Xiaoyan Cai is an Associate Professor in School of Automation at Northwestern Polytechnical  University. She is a member of the IEEE and the CCF. Her research interests include natural language processing and image caption. I am the leader of National Natural Science Foundation of China, MOE (Ministry of Education in China) Project of Humanities and Social Sciences, Natural Science Foundation of Shaanxi Province, etc. I have published about 20 papers. 
								Homepage：https://teacher.nwpu.edu.cn/m/2016010059.html</span></td>
                                </td>
                            </tr>
							
							<tr>
                                <td><img src="img/hzl.jpg" style="max-width: 100%;" /></td>
                                <td style="text-align: justify;"><span class="yahei">Zhongling Huang received the B.Sc. degree from Beijing Normal University, Beijing, China, in 2015, and the Ph.D. degree from University of Chinese Academy of Sciences, Beijing, China, in 2020. She was a visiting Ph.D student in the EO Data Science Department, German Aerospace Center (DLR), Wessling, Germany, in 2019. She is currently an associate professor with the School of Automation, Northwestern Polytechnical University, Xi’an, China. Her research interests include remote sensing, synthetic aperture radar (SAR) target recognition, SAR image understanding, and deep learning. E-mail: huangzhongling@nwpu.edu.cn</span></td>
                                <td><img src="img/xc.jpg" style="max-width: 100%;" /></td>
                                <td style="text-align: justify;"><span class="yahei">Chen Xia received the B.Eng. and Ph.D. degrees from Xidian University, Xi'an, China, in 2010 and 2017, respectively. She is currently an Assistant Professor with the School of Automation, Northwestern Polytechnical University, Xi'an, China. Her research interests include computer vision, deep learning, saliency estimation, and saccadic scanpath prediction and applications in ASD identification. Email:cxia@nwpu.edu.cn</span></td>
                                </td>
                            </tr>
							
											  <tr>
                            <td><img src="img/dl.jpg" style="max-width: 100%;" /></td>
                                <td style="text-align: justify;"><span class="yahei">Lei Du is currently an Assistant Professor in Northwestern Polytechnical University of China. He has published more than 30 papers in top journals and top conferences including Bioinformatics, IEEE TMI, Medical Image Analysis, ISMB, IPMI, MICCAI, BIBM and so on. He is the winner of best Paper Award of BIBM 2018. He is also the PI (principal investigator) of projects of the National Natural Science Foundation of China, Natural Science Foundation of Shaanxi Province and so on. He is the member of the CCF Bioinformatics Committee and the CAA Intelligent Health and Bioinformatics Committee. He also serves BIBM as a Session Chair. Email: dulei@nwpu.edu.cn. Homepage: https://teacher.nwpu.edu.cn/dulei.html</span></td>
                            </tr>



                            <!-- </tr>				 -->
                        </tbody>
                    </table>
                </div>
            </div>

        </div>
        <!-- /.container -->

    </div>
    <!-- /.content-section-a -->
	
	
	<a name="direction"></a>
	<div class="container">
	<div class="row">
                <div class="col-lg-12 col-sm-12">
                    <hr class="section-heading-spacer">
                    <div class="clearfix"></div>
                    <h2 class="section-heading"><span class="yahei">Research Direction</span></h2>
                    <img src="img/fx1_en.jpg" style="max-height: 100%; max-width: 100%;" />
					<table class="table table-striped table-hover " id="paper_list">
                    <thead>
                        <tr>
                            <th class="col-xs-2"><span class="yahei">Selected Publication</span></th>
                            <th><span class="yahei">Title</span></th>
                            <th class="col-xs-2"><span class="yahei">Link</span></th>

                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><img src="img/publication/TMI20.jpg" style="max-height: 100%; max-width: 100%;" /></td>
                            <td>Lei Du, Fang Liu, Kefei Liu, Xiaohui Yao, Shannon L. Risacher, Junwei Han, Andrew J. Saykin, Li Shen. Associating Multi-modal Brain Imaging Phenotypes and Genetic Risk Factors via A Dirty Multi-task Learning Method. IEEE Transactions on Medical Imaging, Early access, 2020.</td>
                            <td> <a
                                    href="https://github.com/shijiezhaonwpu/Brain-and-Medical-Image-Analysis">[PaperLink]</a>
                            </td>
                        </tr>
                        <tr>
                            <td><img src="img/publication/tmm19.jpg" style="max-height: 100%; max-width: 100%;" /></td>
                            <td>Han Wang, Shijie Zhao, Qinglin Dong, Yan Cui, Yaowu Chen, Junwei Han, Li Xie, Tianming Liu, Recognizing Brain States Using Deep Sparse Recurrent Neural Network, IEEE Transactions on Medical Imaging, 4(38):1058-1068, 2019.</td>
                            <td> <a href="https://github.com/shijiezhaonwpu/Brain-and-Medical-Image-Analysis">[PaperLink]</a>
                            </td>
                        </tr>
                        <tr>
                            <td><img src="img/publication/tmm15.jpg" style="max-height: 100%; max-width: 100%;" /></td>
                            <td>Shijie Zhao, Junwei Han, Jinglei Lv, Xi Jiang, Xintao Hu, Bao Ge, Lei Guo, Tianming Liu. Supervised dictionary learning for inferring concurrent brain networks, IEEE Transactions on Medical Imaging, 34(10): 2036-2045, 2015.  </td>
                            <td> <a href="https://github.com/shijiezhaonwpu/Brain-and-Medical-Image-Analysis">[PaperLink]</a>
                            </td>
                        </tr>

						

                        <tr>
                            <td><img src="img/publication/tip13.jpg" style="max-height: 100%; max-width: 100%;" />
                            </td>
                            <td>Junwei Han, Xiang Ji, Xintao Hu, Dajiang Zhu, Kaiming Li, Xi Jiang, Guangbin Cui, Lei Guo, Tianming Liu. Representing and retrieving video shots in human-centric brain imaging space. IEEE Transactions on Image Processing, 22(7): 2723-2736, 2013.</td>
                            <td> <a href="https://github.com/shijiezhaonwpu/Brain-and-Medical-Image-Analysis">[Paperlink]</a> </td>
                        </tr>


                        <tr>
                            <td><img src="img/publication/tip12.jpg" style="max-height: 100%; max-width: 100%;" />
                            </td>
                            <td>Tuo Zhang, Lei Guo, Kaiming Li, Changfeng Jing, Yan Yin, Dajiang Zhu, Guangbin Cui, Lingjiang Li, Tianming Liu. Predicting functional cortical ROIs via DTI-derived fiber shape models. Cerebral cortex, 22(4): 854-864, 2012.</td>
                            <td> <a href="https://github.com/shijiezhaonwpu/Brain-and-Medical-Image-Analysis">[Paperlink]</a> 
                                    </td>
                        </tr>

                    </tbody>
                    </table>
					
					
					<img src="img/fx2_en.jpg" style="max-height: 100%; max-width: 100%;" />
					<table class="table table-striped table-hover " id="paper_list">
                    <thead>
                        <tr>
                            <th class="col-xs-2"><span class="yahei">Selected Publication</span></th>
                            <th><span class="yahei">Title</span></th>
                            <th class="col-xs-2"><span class="yahei">Link</span></th>

                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><img src="img/publication/jprs20.jpg" style="max-height: 100%; max-width: 100%;" /></td>
                            <td>Ke Li, Gang Wan, Gong Cheng, Liqiu Meng, Junwei Han. Object detection in optical remote sensing images: a survey and a new benchmark. ISPRS Journal of Photogrammetry and Remote Sensing (<font color="red">JPRS</font>), 2020.</td>
                            <td> <a
                                    href="https://arxiv.org/abs/1909.00133">[PaperLink]</a>
									<a
                                    href="https://gcheng-nwpu.github.io/datasets">[Dataset]</a>
                            </td>
                        </tr>
                        <tr>
                            <td><img src="img/publication/TGRS18.jpg" style="max-height: 60%; max-width: 100%;" /></td>
                            <td>Gong Cheng, Ceyuan Yang, Xiwen Yao, Lei Guo, Junwei Han. When deep learning meets metric learning: remote sensing image scene classification via learning discriminative CNNs. IEEE Transactions on Geoscience and Remote Sensing (<font color="red">TGRS</font>), 2018.</td>
                            <td> <a href="https://ieeexplore.ieee.org/document/8252784">[PaperLink]</a>
							<a href="https://github.com/limbo0000/PairLoss">[Code]</a>
                            </td>
                        </tr>
                        <tr>
                            <td><img src="img/publication/PIEE17.jpg" style="max-height: 60%; max-width: 100%;" /></td>
                            <td>Gong Cheng, Junwei Han, Xiaoqiang Lu. Remote sensing image scene classification: benchmark and state of the art. Proceedings of the IEEE, 2017.</td>
                            <td> <a href="https://ieeexplore.ieee.org/document/7891544">[PaperLink]</a><a
                                    href="https://gcheng-nwpu.github.io/datasets">[Dataset]</a>
                            </td>
                        </tr>

						

                        <tr>
                            <td><img src="img/publication/TGRS16.jpg" style="max-height: 60%; max-width: 100%;" />
                            </td>
                            <td>Gong Cheng, Peicheng Zhou, Junwei Han. Learning rotation-invariant convolutional neural networks for object detection in VHR optical remote sensing images. IEEE Transactions on Geoscience and Remote Sensing (<font color="red">TGRS</font>), 2016.</td>
                            <td> <a href="https://ieeexplore.ieee.org/document/7560644">[PaperLink]</a> <a
                                    href="https://pan.baidu.com/s/158JPjYQvXwnkrAqKF72Jgg">[Code]</a></td>
                        </tr>


                   

                        <tr>
                            <td><img src="img/publication/tgrs.png" style="max-height: 100%; max-width: 100%;" /></td>
                            <td>Junwei Han, Dingwen Zhang, Gong Cheng, Lei Guo, Jinchang Ren. Object Detection in
                                Optical Remote Sensing Images Based on Weakly Supervised Learning and High-Level Feature
                                Learning. IEEE Transactions on Geoscience and Remote Sensing (<font color="red">T-GRS
                                </font>), 2015.
                            </td>
                            <td> <a href="https://ieeexplore.ieee.org/document/6991537">[PaperLink]</a> 
							<a href="http://pan.baidu.com/s/1pLa0SmZ">[Dataset]</a></td>
                        </tr>
                    </tbody>
					</table>
					
					<img src="img/fx3_en.jpg" style="max-height: 100%; max-width: 100%;" />
					<table class="table table-striped table-hover " id="paper_list">
                    <thead>
                        <tr>
                            <th class="col-xs-2"><span class="yahei">Selected Publication</span></th>
                            <th><span class="yahei">Title</span></th>
                            <th class="col-xs-2"><span class="yahei">Link</span></th>

                        </tr>
                    </thead>
                    <tbody>
					    <tr>
                            <td><img src="img/publication/niancvpr2020.png" style="max-height: 100%; max-width: 100%;" /></td>
                            <td>Nian Liu, Ni Zhang, and Junwei Han. Learning Selective Self-Mutual Attention for RGB-D Saliency Detection. IEEE Conference on
                                Computer Vision and Pattern Recognition (<font color="red">CVPR</font>), 2020.</td>
                            <td> <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Liu_Learning_Selective_Self-Mutual_Attention_for_RGB-D_Saliency_Detection_CVPR_2020_paper.pdf">[PaperLink]</a>
                            <a href="https://github.com/nnizhang/S2MA">[Code]</a>
							</td>
                        </tr>
					
					
                        <tr>
                            <td><img src="img/publication/PAMI19.jpg" style="max-height: 100%; max-width: 100%;" /></td>
                            <td>Dingwen Zhang, Junwei Han, Yu Zhang, Dong Xu. Synthesizing Supervision for
                                Learning Deep Saliency Network without Human Annotation. IEEE Transactions on Pattern
                                Analysis and Machine Intelligence (<font color="red">T-PAMI</font>), 2020.
                                </td>
                            <td> <a
                                    href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhang_Supervision_by_Fusion_ICCV_2017_paper.pdf">[PaperLink]</a>
									<a
                                    href="https://github.com/zhangyuygss/SVFSal.caffe">[Code]</a>
                            </td>
                        </tr>
						
                        <tr>
                            <td><img src="img/publication/nianTIP2020.jpg" style="max-height: 100%; max-width: 100%;" /></td>
                            <td>Nian Liu, Junwei Han, and Ming-Hsuan Yang. PiCANet: Pixel-wise Contextual Attention Learning for Accurate Saliency Detection. IEEE Transactions on
                                Image Processing (<font color="red">T-IP</font>), 2020.
                                </br>Nian Liu, Junwei Han, and Ming-Hsuan Yang. PiCANet: Learning Pixel-wise Contextual Attention for Saliency Detection. IEEE Conference on
                                Computer Vision and Pattern Recognition (<font color="red">CVPR</font>), 2018. </td>
                            <td> <a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Liu_PiCANet_Learning_Pixel-Wise_CVPR_2018_paper.pdf">[PaperLink]</a>
							<a href="https://github.com/nian-liu/PiCANet">[Code]</a>
                            </td>
                        </tr>
                        <tr>
                            <td><img src="img/publication/IJCV18.png" style="max-height: 100%; max-width: 100%;" /></td>
                            <td><b>Dingwen Zhang</b>, Junwei Han, Long Zhao, Duyu Meng. Leveraging Prior-Knowledge for
                                Weakly Supervised Object Detection Under a Collaborative Self-Paced Curriculum Learning
                                Framework. International Journal of Computer Vision, (<font color="red">IJCV</font>),
                                2019.
                             </td>
                            <td> <a href="https://link.springer.com/article/10.1007/s11263-018-1112-4">[PaperLink]</a><a
                                    href="https://drive.google.com/open?id=1X1zPAn6PuMIeddjetxGRDEeVJg5joWfM">[Models]</a>
                            </td>
                        </tr>

						

                        <tr>
                            <td><img src="img/publication/pamiCosal.png" style="max-height: 100%; max-width: 100%;" />
                            </td>
                            <td>Dingwen Zhang, Deyu Meng, Junwei Han: Co-Saliency Detection via a Self-Paced
                                Multiple-Instance Learning Framework. IEEE Transactions on Pattern Analysis and Machine
                                Intelligence (<font color="red">T-PAMI</font>), 2017.
                                </td>
                            <td> <a href="http://pan.baidu.com/s/1hrS7KSO">[Dataset]</a> <a
                                    href="http://pan.baidu.com/s/1o7XLjMM">[Results]</a> <a
                                    href="https://pan.baidu.com/s/1eTQLFCu">[Evaluation Metrics]</a></td>
                        </tr>


                    </tbody>
					</table>
                </div>
                
    </div>
	</div>
	
	
	
	

    <!-- /.content-section-b -->

    <a name="student"></a>
    <div class="content-section-b">

        <div class="container">

            <div class="row">
                <div>
                    <hr class="section-heading-spacer">
                    <div class="clearfix"></div>
                    <h2 class="section-heading"><span class="yahei">Recruitment and Employment:</span></h2>
					<img src="img/5_en.jpg" style="max-height: 100%; max-width: 100%;" />
					<img src="img/6_en.jpg" style="max-height: 100%; max-width: 100%;" />
                </div>
            </div>

        </div>
        <!-- /.container -->

    </div>
    <!-- /.content-section-a -->

   
    <!-- /.banner -->

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <ul class="list-inline">
                        <li>
                            <a href="#"><span class="yahei">Top</span></a>
                        </li>
                        <li class="footer-menu-divider">&sdot;</li>
                        <li>
                            <a href="#about"><span class="yahei">About</span></a>
                        </li>
                        <li class="footer-menu-divider">&sdot;</li>
                        <li>
                            <a href="#publications"><span class="yahei">People</span></a>
                        </li>
                        <li class="footer-menu-divider">&sdot;</li>
                        <li>
                            <a href="#direction"><span class="yahei">Research Direction</span></a>
                        </li>
                        <li class="footer-menu-divider">&sdot;</li>
                        <li>
                            <a href="#student"><span class="yahei">Recruitment and Employment</span></a>
                        </li>
                    </ul>
                    <p class="copyright text-muted small">Copyright &copy; BRAIN Lab, 2022. All Rights Reserved</p>
                </div>
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

</body>

</html>